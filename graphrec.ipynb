{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRec: A Graph Neural Network Framework for Athletic Recovery Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parthkapur/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing, GCNConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple\n",
    "import math\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"Processes multi-modal athletic recovery data into graph representations\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str = \"pmdata\"):\n",
    "        self.data_path = Path(data_path)\n",
    "        self.scalers = {}\n",
    "        self.athlete_mapping = {}\n",
    "        \n",
    "    def calculate_hrv_metrics(self, hr_data: List[Dict]) -> Dict:\n",
    "        \"\"\"Calculate Heart Rate Variability metrics from minute-by-minute HR data\"\"\"\n",
    "        try:\n",
    "            bpm_values = [entry['value']['bpm'] for entry in hr_data if 'value' in entry and 'bpm' in entry['value']]\n",
    "            \n",
    "            if len(bpm_values) < 50:\n",
    "                return {'hrv_rmssd': 0, 'hrv_pnn50': 0, 'hrv_mean': np.mean(bpm_values) if bpm_values else 60}\n",
    "            \n",
    "            # Calculate RR intervals from BPM\n",
    "            rr_intervals = [60000 / bpm for bpm in bpm_values if bpm > 0]\n",
    "            \n",
    "            if len(rr_intervals) < 2:\n",
    "                return {'hrv_rmssd': 0, 'hrv_pnn50': 0, 'hrv_mean': np.mean(bpm_values)}\n",
    "            \n",
    "            # RMSSD calculation\n",
    "            successive_diffs = [abs(rr_intervals[i+1] - rr_intervals[i]) for i in range(len(rr_intervals)-1)]\n",
    "            rmssd = np.sqrt(np.mean([diff**2 for diff in successive_diffs])) if successive_diffs else 0\n",
    "            \n",
    "            # pNN50 calculation\n",
    "            pnn50 = len([diff for diff in successive_diffs if diff > 50]) / len(successive_diffs) * 100 if successive_diffs else 0\n",
    "            \n",
    "            return {\n",
    "                'hrv_rmssd': rmssd,\n",
    "                'hrv_pnn50': pnn50,\n",
    "                'hrv_mean': np.mean(bpm_values)\n",
    "            }\n",
    "        except Exception:\n",
    "            return {'hrv_rmssd': 0, 'hrv_pnn50': 0, 'hrv_mean': 60}\n",
    "    \n",
    "    def extract_sleep_features(self, sleep_data: List[Dict]) -> Dict:\n",
    "        \"\"\"Extract sleep architecture features as described in the paper\"\"\"\n",
    "        if not sleep_data:\n",
    "            return self._default_sleep_features()\n",
    "        \n",
    "        try:\n",
    "            latest_sleep = sleep_data[-1]\n",
    "            levels = latest_sleep.get('levels', {})\n",
    "            summary = levels.get('summary', {})\n",
    "            \n",
    "            features = {\n",
    "                'sleep_duration': latest_sleep.get('timeInBed', 0) / 60,\n",
    "                'sleep_efficiency': latest_sleep.get('efficiency', 0),\n",
    "                'minutes_to_sleep': latest_sleep.get('minutesToFallAsleep', 0),\n",
    "                'sleep_deep_min': summary.get('deep', {}).get('minutes', 0),\n",
    "                'sleep_rem_min': summary.get('rem', {}).get('minutes', 0),\n",
    "                'sleep_light_min': summary.get('light', {}).get('minutes', 0),\n",
    "                'sleep_wake_min': summary.get('wake', {}).get('minutes', 0),\n",
    "                'sleep_deep_pct': summary.get('deep', {}).get('minutes', 0) / max(latest_sleep.get('minutesAsleep', 1), 1) * 100,\n",
    "                'sleep_rem_pct': summary.get('rem', {}).get('minutes', 0) / max(latest_sleep.get('minutesAsleep', 1), 1) * 100,\n",
    "                'sleep_restlessness': len(levels.get('data', [])),\n",
    "            }\n",
    "            \n",
    "            return features\n",
    "        except Exception:\n",
    "            return self._default_sleep_features()\n",
    "    \n",
    "    def _default_sleep_features(self) -> Dict:\n",
    "        return {\n",
    "            'sleep_duration': 7.0,\n",
    "            'sleep_efficiency': 85,\n",
    "            'minutes_to_sleep': 15,\n",
    "            'sleep_deep_min': 90,\n",
    "            'sleep_rem_min': 90,\n",
    "            'sleep_light_min': 240,\n",
    "            'sleep_wake_min': 20,\n",
    "            'sleep_deep_pct': 20,\n",
    "            'sleep_rem_pct': 20,\n",
    "            'sleep_restlessness': 15\n",
    "        }\n",
    "    \n",
    "    def extract_activity_features(self, activity_data: List[Dict], hr_zones_data: List[Dict], calories_data: List[Dict]) -> Dict:\n",
    "        \"\"\"Extract physical activity features including heart rate zones\"\"\"\n",
    "        try:\n",
    "            hr_zones = {'zone_1': 0, 'zone_2': 0, 'zone_3': 0, 'zone_4': 0}\n",
    "            if hr_zones_data:\n",
    "                latest_zones = hr_zones_data[-1].get('value', {}).get('valuesInZones', {})\n",
    "                hr_zones = {\n",
    "                    'zone_1': latest_zones.get('IN_DEFAULT_ZONE_1', 0),\n",
    "                    'zone_2': latest_zones.get('IN_DEFAULT_ZONE_2', 0), \n",
    "                    'zone_3': latest_zones.get('IN_DEFAULT_ZONE_3', 0),\n",
    "                    'zone_4': latest_zones.get('ABOVE_DEFAULT_ZONE_3', 0)\n",
    "                }\n",
    "            \n",
    "            recent_exercises = [ex for ex in activity_data if 'startTime' in ex][-7:] if activity_data else []\n",
    "            total_exercise_min = sum(ex.get('duration', 0) for ex in recent_exercises) / 60000\n",
    "            avg_hr = np.mean([ex.get('averageHeartRate', 0) for ex in recent_exercises if ex.get('averageHeartRate', 0) > 0]) if recent_exercises else 0\n",
    "            total_calories = sum(ex.get('calories', 0) for ex in recent_exercises)\n",
    "            \n",
    "            daily_calories = 0\n",
    "            if calories_data:\n",
    "                daily_calories = sum(float(entry.get('value', 0)) for entry in calories_data[-1440:])\n",
    "            \n",
    "            return {\n",
    "                'exercise_duration_week': total_exercise_min,\n",
    "                'avg_exercise_hr': avg_hr,\n",
    "                'exercise_calories_week': total_calories,\n",
    "                'daily_caloric_expenditure': daily_calories,\n",
    "                'hr_zone_1_min': hr_zones['zone_1'],\n",
    "                'hr_zone_2_min': hr_zones['zone_2'],\n",
    "                'hr_zone_3_min': hr_zones['zone_3'],\n",
    "                'hr_zone_4_min': hr_zones['zone_4'],\n",
    "                'training_stress_score': (hr_zones['zone_3'] * 2 + hr_zones['zone_4'] * 3) / 60\n",
    "            }\n",
    "        except Exception:\n",
    "            return {\n",
    "                'exercise_duration_week': 0,\n",
    "                'avg_exercise_hr': 0,\n",
    "                'exercise_calories_week': 0,\n",
    "                'daily_caloric_expenditure': 2000,\n",
    "                'hr_zone_1_min': 0,\n",
    "                'hr_zone_2_min': 0,\n",
    "                'hr_zone_3_min': 0,\n",
    "                'hr_zone_4_min': 0,\n",
    "                'training_stress_score': 0\n",
    "            }\n",
    "    \n",
    "    def load_participant_data(self, participant_id: str) -> List[Dict]:\n",
    "        \"\"\"Load and process all data for a single participant\"\"\"\n",
    "        p_path = self.data_path / participant_id\n",
    "        if not p_path.exists():\n",
    "            return []\n",
    "        \n",
    "        # Load all data files\n",
    "        data_files = {\n",
    "            'wellness': p_path / 'pmsys' / 'wellness.csv',\n",
    "            'srpe': p_path / 'pmsys' / 'srpe.csv', \n",
    "            'injury': p_path / 'pmsys' / 'injury.csv',\n",
    "            'heart_rate': p_path / 'fitbit' / 'heart_rate.json',\n",
    "            'sleep': p_path / 'fitbit' / 'sleep.json',\n",
    "            'sleep_score': p_path / 'fitbit' / 'sleep_score.csv',\n",
    "            'exercise': p_path / 'fitbit' / 'exercise.json',\n",
    "            'hr_zones': p_path / 'fitbit' / 'time_in_heart_rate_zones.json',\n",
    "            'calories': p_path / 'fitbit' / 'calories.json',\n",
    "            'resting_hr': p_path / 'fitbit' / 'resting_heart_rate.json'\n",
    "        }\n",
    "        \n",
    "        # Load JSON files\n",
    "        json_data = {}\n",
    "        for key in ['heart_rate', 'sleep', 'exercise', 'hr_zones', 'calories', 'resting_hr']:\n",
    "            try:\n",
    "                if data_files[key].exists():\n",
    "                    with open(data_files[key], 'r') as f:\n",
    "                        json_data[key] = json.load(f)\n",
    "                else:\n",
    "                    json_data[key] = []\n",
    "            except Exception:\n",
    "                json_data[key] = []\n",
    "        \n",
    "        # Load CSV files\n",
    "        csv_data = {}\n",
    "        for key in ['wellness', 'srpe', 'injury', 'sleep_score']:\n",
    "            try:\n",
    "                if data_files[key].exists():\n",
    "                    csv_data[key] = pd.read_csv(data_files[key])\n",
    "                else:\n",
    "                    csv_data[key] = pd.DataFrame()\n",
    "            except Exception:\n",
    "                csv_data[key] = pd.DataFrame()\n",
    "        \n",
    "        # Process wellness data (primary temporal anchor)\n",
    "        samples = []\n",
    "        if not csv_data['wellness'].empty:\n",
    "            for _, wellness_row in csv_data['wellness'].iterrows():\n",
    "                try:\n",
    "                    sample_date = pd.to_datetime(wellness_row['effective_time_frame']).date()\n",
    "                    \n",
    "                    # Extract wellness features (subjective)\n",
    "                    wellness_features = {\n",
    "                        'fatigue': int(wellness_row['fatigue']),\n",
    "                        'mood': int(wellness_row['mood']),\n",
    "                        'readiness': int(wellness_row['readiness']),\n",
    "                        'sleep_quality_subj': int(wellness_row['sleep_quality']),\n",
    "                        'soreness': int(wellness_row['soreness']),\n",
    "                        'stress': int(wellness_row['stress']),\n",
    "                        'sleep_duration_subj': int(wellness_row['sleep_duration_h'])\n",
    "                    }\n",
    "                    \n",
    "                    # Extract physiological features\n",
    "                    hrv_features = self.calculate_hrv_metrics(json_data['heart_rate'])\n",
    "                    sleep_features = self.extract_sleep_features(json_data['sleep'])\n",
    "                    activity_features = self.extract_activity_features(\n",
    "                        json_data['exercise'], \n",
    "                        json_data['hr_zones'],\n",
    "                        json_data['calories']\n",
    "                    )\n",
    "                    \n",
    "                    # Get resting heart rate\n",
    "                    resting_hr = 60\n",
    "                    if json_data['resting_hr']:\n",
    "                        resting_hr = json_data['resting_hr'][-1].get('value', {}).get('restingHeartRate', 60)\n",
    "                    \n",
    "                    # Combine all features\n",
    "                    all_features = {\n",
    "                        **wellness_features,\n",
    "                        **hrv_features,\n",
    "                        **sleep_features,\n",
    "                        **activity_features,\n",
    "                        'resting_heart_rate': resting_hr,\n",
    "                        'participant_id': participant_id,\n",
    "                        'date': sample_date\n",
    "                    }\n",
    "                    \n",
    "                    samples.append(all_features)\n",
    "                    \n",
    "                except Exception:\n",
    "                    continue\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def augment_sample(self, sample: Dict, augmentation_strength: float = 0.1) -> Dict:\n",
    "        \"\"\"Apply data augmentation as described in Section 3.6\"\"\"\n",
    "        augmented = sample.copy()\n",
    "        \n",
    "        # Physiological noise augmentation (Gaussian noise)\n",
    "        physio_keys = ['hrv_rmssd', 'hrv_pnn50', 'hrv_mean', 'resting_heart_rate',\n",
    "                      'sleep_duration', 'sleep_efficiency', 'exercise_duration_week']\n",
    "        \n",
    "        for key in physio_keys:\n",
    "            if key in augmented:\n",
    "                noise = np.random.normal(0, augmentation_strength * abs(augmented[key]))\n",
    "                augmented[key] = max(0, augmented[key] + noise)\n",
    "        \n",
    "        # Subjective data augmentation (discrete modifications)\n",
    "        subjective_keys = ['fatigue', 'mood', 'readiness', 'sleep_quality_subj', 'soreness', 'stress']\n",
    "        \n",
    "        for key in subjective_keys:\n",
    "            if key in augmented and np.random.random() < 0.1:\n",
    "                current_val = augmented[key]\n",
    "                change = np.random.choice([-1, 0, 1])\n",
    "                if key in ['fatigue', 'soreness', 'stress']:\n",
    "                    new_val = np.clip(current_val + change, 1, 4)\n",
    "                else:\n",
    "                    new_val = np.clip(current_val + change, 1, 8)\n",
    "                augmented[key] = int(new_val)\n",
    "        \n",
    "        return augmented\n",
    "    \n",
    "    def create_augmented_samples(self, samples: List[Dict], num_augmentations: int = 2) -> List[Dict]:\n",
    "        \"\"\"Create augmented versions of samples for training\"\"\"\n",
    "        augmented_samples = samples.copy()\n",
    "        \n",
    "        for _ in range(num_augmentations):\n",
    "            for sample in samples:\n",
    "                augmented = self.augment_sample(sample, augmentation_strength=0.1)\n",
    "                augmented_samples.append(augmented)\n",
    "        \n",
    "        return augmented_samples\n",
    "    \n",
    "    def create_recovery_graphs(self, samples: List[Dict], participant_id: str, athlete_idx: int) -> List[Data]:\n",
    "        \"\"\"Create graph representations for recovery optimization\"\"\"\n",
    "        if len(samples) < 7:\n",
    "            return []\n",
    "        \n",
    "        graphs = []\n",
    "        samples = sorted(samples, key=lambda x: x['date'])\n",
    "        \n",
    "        # Create temporal windows (7-day sliding window)\n",
    "        for i in range(6, len(samples)):\n",
    "            try:\n",
    "                current_sample = samples[i]\n",
    "                history_samples = samples[i-6:i]\n",
    "                \n",
    "                # Create multi-modal graph\n",
    "                node_features, edge_index, edge_attr = self._build_recovery_graph(\n",
    "                    current_sample, history_samples, athlete_idx\n",
    "                )\n",
    "                \n",
    "                # Define recovery targets (Eq. 1-4 in paper)\n",
    "                targets = self._create_recovery_targets(current_sample, samples[i:i+3] if i+3 < len(samples) else [current_sample])\n",
    "                \n",
    "                graph = Data(\n",
    "                    x=torch.tensor(node_features, dtype=torch.float32),\n",
    "                    edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
    "                    edge_attr=torch.tensor(edge_attr, dtype=torch.float32),\n",
    "                    y=torch.tensor(targets, dtype=torch.float32),\n",
    "                    participant_id=participant_id,\n",
    "                    athlete_idx=athlete_idx,\n",
    "                    date=current_sample['date']\n",
    "                )\n",
    "                \n",
    "                graphs.append(graph)\n",
    "                \n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        return graphs\n",
    "    \n",
    "    def _build_recovery_graph(self, current: Dict, history: List[Dict], athlete_idx: int) -> Tuple:\n",
    "        \"\"\"Build multi-modal recovery graph with specialized node types (Section 3.2)\"\"\"\n",
    "        \n",
    "        nodes = []\n",
    "        \n",
    "        # Current physiological nodes (0-2)\n",
    "        physio_node_1 = [  # HRV & Heart Rate\n",
    "            current['hrv_rmssd'], current['hrv_pnn50'], current['hrv_mean'],\n",
    "            current['resting_heart_rate'], current['avg_exercise_hr']\n",
    "        ]\n",
    "        \n",
    "        physio_node_2 = [  # Sleep architecture\n",
    "            current['sleep_duration'], current['sleep_efficiency'], current['minutes_to_sleep'],\n",
    "            current['sleep_deep_min'], current['sleep_rem_min'], current['sleep_light_min'],\n",
    "            current['sleep_deep_pct'], current['sleep_rem_pct'], current['sleep_restlessness']\n",
    "        ]\n",
    "        \n",
    "        physio_node_3 = [  # Activity & training\n",
    "            current['exercise_duration_week'], current['exercise_calories_week'],\n",
    "            current['daily_caloric_expenditure'], current['training_stress_score'],\n",
    "            current['hr_zone_1_min'], current['hr_zone_2_min'], \n",
    "            current['hr_zone_3_min'], current['hr_zone_4_min']\n",
    "        ]\n",
    "        \n",
    "        # Current subjective nodes (3-5)\n",
    "        subj_node_1 = [  # Wellness perception\n",
    "            current['fatigue'], current['mood'], current['stress'],\n",
    "            current['sleep_quality_subj'], current['sleep_duration_subj']\n",
    "        ]\n",
    "        \n",
    "        subj_node_2 = [  # Performance readiness\n",
    "            current['readiness'], current['soreness']\n",
    "        ]\n",
    "        \n",
    "        subj_node_3 = [  # Recovery status (derived)\n",
    "            (current['readiness'] - current['fatigue']) / 8,\n",
    "            current['mood'] / 4,\n",
    "            (4 - current['stress']) / 4\n",
    "        ]\n",
    "        \n",
    "        # Historical temporal nodes (6-11)\n",
    "        history_nodes = []\n",
    "        for day_data in history:\n",
    "            trend_features = [\n",
    "                day_data['readiness'] / 8,\n",
    "                day_data['fatigue'] / 4,\n",
    "                day_data['sleep_quality_subj'] / 4,\n",
    "                day_data['training_stress_score'] / 10\n",
    "            ]\n",
    "            history_nodes.append(trend_features)\n",
    "        \n",
    "        # Pad if insufficient history\n",
    "        while len(history_nodes) < 6:\n",
    "            history_nodes.insert(0, [0.5, 0.5, 0.5, 0.0])\n",
    "        \n",
    "        # Athlete identity node (12)\n",
    "        athlete_features = [\n",
    "            athlete_idx / 16,\n",
    "            np.mean([h[0] for h in history_nodes]),\n",
    "            np.mean([h[1] for h in history_nodes]),\n",
    "            np.std([h[0] for h in history_nodes]) if len(history_nodes) > 1 else 0\n",
    "        ]\n",
    "        \n",
    "        # Combine all nodes\n",
    "        nodes = [physio_node_1, physio_node_2, physio_node_3,\n",
    "                 subj_node_1, subj_node_2, subj_node_3] + history_nodes + [athlete_features]\n",
    "        \n",
    "        # Pad nodes to consistent size\n",
    "        max_node_size = max(len(node) for node in nodes)\n",
    "        for i, node in enumerate(nodes):\n",
    "            if len(node) < max_node_size:\n",
    "                nodes[i] = node + [0.0] * (max_node_size - len(node))\n",
    "        \n",
    "        edge_index, edge_attr = self._create_recovery_edges(current, history)\n",
    "        \n",
    "        return nodes, edge_index, edge_attr\n",
    "    \n",
    "    def _create_recovery_edges(self, current: Dict, history: List[Dict]) -> Tuple:\n",
    "        \"\"\"Create meaningful edge connections with relationship weights\"\"\"\n",
    "        \n",
    "        edges = []\n",
    "        edge_weights = []\n",
    "        \n",
    "        # Physiological interconnections\n",
    "        physio_connections = [\n",
    "            (0, 1, 0.8),  # HRV ↔ Sleep\n",
    "            (0, 2, 0.6),  # HRV ↔ Activity\n",
    "            (1, 2, 0.7),  # Sleep ↔ Activity\n",
    "        ]\n",
    "        \n",
    "        # Subjective interconnections  \n",
    "        subj_connections = [\n",
    "            (3, 4, 0.9),  # Wellness ↔ Readiness\n",
    "            (3, 5, 0.8),  # Wellness ↔ Recovery status\n",
    "            (4, 5, 0.9),  # Readiness ↔ Recovery status\n",
    "        ]\n",
    "        \n",
    "        # Cross-modal connections (physio ↔ subjective)\n",
    "        cross_connections = [\n",
    "            (0, 3, 0.7),  # HRV → Wellness\n",
    "            (1, 3, 0.8),  # Sleep → Wellness  \n",
    "            (1, 4, 0.9),  # Sleep → Readiness\n",
    "            (2, 4, 0.6),  # Activity → Readiness\n",
    "            (2, 5, 0.7),  # Activity → Recovery status\n",
    "        ]\n",
    "        \n",
    "        # Temporal connections (history → current)\n",
    "        temporal_connections = []\n",
    "        for i, hist_idx in enumerate(range(6, 12)):\n",
    "            temporal_connections.extend([\n",
    "                (hist_idx, 4, 0.5 + i * 0.05),\n",
    "                (hist_idx, 5, 0.4 + i * 0.05),\n",
    "            ])\n",
    "        \n",
    "        # Athlete identity connections\n",
    "        identity_connections = [\n",
    "            (12, 3, 0.6),  # Athlete → Wellness  \n",
    "            (12, 4, 0.7),  # Athlete → Readiness\n",
    "            (12, 5, 0.8),  # Athlete → Recovery status\n",
    "        ]\n",
    "        \n",
    "        all_connections = physio_connections + subj_connections + cross_connections + temporal_connections + identity_connections\n",
    "        \n",
    "        # Create bidirectional edges\n",
    "        for src, dst, weight in all_connections:\n",
    "            edges.extend([(src, dst), (dst, src)])\n",
    "            edge_weights.extend([weight, weight * 0.9])\n",
    "        \n",
    "        edge_index = [[src for src, dst in edges], [dst for src, dst in edges]]\n",
    "        \n",
    "        return edge_index, edge_weights\n",
    "    \n",
    "    def _create_recovery_targets(self, current: Dict, future: List[Dict]) -> List[float]:\n",
    "        \"\"\"Create multi-task recovery targets (Section 3.1)\"\"\"\n",
    "        \n",
    "        # Primary target: Next-day readiness prediction\n",
    "        next_day_readiness = current['readiness'] / 8.0\n",
    "        \n",
    "        # Secondary target: Recovery quality score\n",
    "        recovery_score = (\n",
    "            (8 - current['fatigue']) / 8 * 0.3 +\n",
    "            current['mood'] / 4 * 0.2 +\n",
    "            current['readiness'] / 8 * 0.4 +\n",
    "            (4 - current['stress']) / 4 * 0.1\n",
    "        )\n",
    "        \n",
    "        # Tertiary target: Training readiness\n",
    "        if current['readiness'] >= 7 and current['fatigue'] <= 2:\n",
    "            training_readiness = 3.0\n",
    "        elif current['readiness'] >= 5 and current['fatigue'] <= 3:\n",
    "            training_readiness = 2.0\n",
    "        elif current['readiness'] >= 3:\n",
    "            training_readiness = 1.0\n",
    "        else:\n",
    "            training_readiness = 0.0\n",
    "        \n",
    "        # Quaternary target: Overreaching risk\n",
    "        overreach_risk = 0.0\n",
    "        if current['fatigue'] >= 3 and current['readiness'] <= 4:\n",
    "            overreach_risk = 0.8\n",
    "        elif current['fatigue'] >= 3 or current['readiness'] <= 5:\n",
    "            overreach_risk = 0.4\n",
    "        \n",
    "        return [next_day_readiness, recovery_score, training_readiness / 3.0, overreach_risk]\n",
    "    \n",
    "    def process_all_participants(self) -> Tuple[List[Data], Dict]:\n",
    "        \"\"\"Process all participants and create recovery graphs with caching\"\"\"\n",
    "        import pickle\n",
    "        import os\n",
    "        \n",
    "        cache_file = 'processed_graphs_cache.pkl'\n",
    "        \n",
    "        if os.path.exists(cache_file):\n",
    "            try:\n",
    "                cache_time = os.path.getmtime(cache_file)\n",
    "                data_dir_time = os.path.getmtime(self.data_path)\n",
    "                \n",
    "                newest_data_time = data_dir_time\n",
    "                for p in self.data_path.iterdir():\n",
    "                    if p.is_dir() and p.name.startswith('p'):\n",
    "                        newest_data_time = max(newest_data_time, os.path.getmtime(p))\n",
    "                \n",
    "                if cache_time > newest_data_time:\n",
    "                    with open(cache_file, 'rb') as f:\n",
    "                        cached_data = pickle.load(f)\n",
    "                        all_graphs = cached_data['graphs']\n",
    "                        participant_stats = cached_data['stats']\n",
    "                        self.athlete_mapping = cached_data['athlete_mapping']\n",
    "                    \n",
    "                    return all_graphs, participant_stats\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        all_graphs = []\n",
    "        participant_stats = {}\n",
    "        \n",
    "        participants = [p for p in self.data_path.iterdir() if p.is_dir() and p.name.startswith('p')]\n",
    "        participants = sorted(participants, key=lambda x: int(x.name[1:]))\n",
    "        \n",
    "        self.athlete_mapping = {p.name: i for i, p in enumerate(participants)}\n",
    "        \n",
    "        for participant_path in participants:\n",
    "            participant_id = participant_path.name\n",
    "            athlete_idx = self.athlete_mapping[participant_id]\n",
    "            \n",
    "            samples = self.load_participant_data(participant_id)\n",
    "            \n",
    "            if not samples:\n",
    "                continue\n",
    "            \n",
    "            graphs = self.create_recovery_graphs(samples, participant_id, athlete_idx)\n",
    "            all_graphs.extend(graphs)\n",
    "            \n",
    "            participant_stats[participant_id] = {\n",
    "                'samples': len(samples),\n",
    "                'graphs': len(graphs),\n",
    "                'date_range': (min(s['date'] for s in samples), max(s['date'] for s in samples)) if samples else None\n",
    "            }\n",
    "        \n",
    "        # Save processed data to cache\n",
    "        try:\n",
    "            cache_data = {\n",
    "                'graphs': all_graphs,\n",
    "                'stats': participant_stats,\n",
    "                'athlete_mapping': self.athlete_mapping\n",
    "            }\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        return all_graphs, participant_stats\n",
    "    \n",
    "    def create_contrastive_pairs(self, graphs: List[Data]) -> List[Tuple[Data, Data]]:\n",
    "        \"\"\"Create positive pairs for contrastive learning (Section 3.5)\"\"\"\n",
    "        pairs = []\n",
    "        \n",
    "        # Group graphs by participant\n",
    "        participant_graphs = {}\n",
    "        for graph in graphs:\n",
    "            pid = graph.participant_id\n",
    "            if pid not in participant_graphs:\n",
    "                participant_graphs[pid] = []\n",
    "            participant_graphs[pid].append(graph)\n",
    "        \n",
    "        # Create positive pairs within same participant\n",
    "        for pid, p_graphs in participant_graphs.items():\n",
    "            if len(p_graphs) < 2:\n",
    "                continue\n",
    "                \n",
    "            p_graphs.sort(key=lambda x: x.date)\n",
    "            \n",
    "            # Pairs of temporally adjacent samples\n",
    "            for i in range(len(p_graphs) - 1):\n",
    "                pairs.append((p_graphs[i], p_graphs[i + 1]))\n",
    "                \n",
    "            # Pairs of samples within a week\n",
    "            for i in range(len(p_graphs)):\n",
    "                for j in range(i + 1, min(i + 8, len(p_graphs))):\n",
    "                    if abs((p_graphs[i].date - p_graphs[j].date).days) <= 7:\n",
    "                        pairs.append((p_graphs[i], p_graphs[j]))\n",
    "        \n",
    "        return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Scale Temporal Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleTemporalConv(nn.Module):\n",
    "    \"\"\"Multi-scale temporal convolution for capturing different time patterns\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels: int, out_channels: int, scales: List[int] = [1, 3, 5, 7]):\n",
    "        super().__init__()\n",
    "        self.scales = scales\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels, out_channels // len(scales), \n",
    "                     kernel_size=min(k, in_channels), padding=min(k, in_channels)//2)\n",
    "            for k in scales\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(out_channels)\n",
    "        self.activation = nn.GELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, in_channels)\n",
    "        x = x.transpose(1, 2)  # (batch_size, in_channels, seq_len)\n",
    "        \n",
    "        outputs = []\n",
    "        for conv in self.convs:\n",
    "            conv_out = conv(x)\n",
    "            outputs.append(conv_out)\n",
    "        \n",
    "        x = torch.cat(outputs, dim=1)  # (batch_size, out_channels, seq_len)\n",
    "        x = x.transpose(1, 2)  # (batch_size, seq_len, out_channels)\n",
    "        \n",
    "        return self.activation(self.norm(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adaptive Graph Structure Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveGraphLearner(nn.Module):\n",
    "    \"\"\"Learn personalized graph structures for each athlete\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.feature_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        # Bilinear edge predictor (Equation 1)\n",
    "        self.edge_predictor = nn.Bilinear(hidden_dim, hidden_dim, 1)\n",
    "        self.sparsity_threshold = 0.3\n",
    "        \n",
    "    def forward(self, node_features, athlete_idx=None):\n",
    "        # Encode node features\n",
    "        encoded_features = self.feature_encoder(node_features)\n",
    "        \n",
    "        # Compute pairwise edge probabilities\n",
    "        num_nodes = encoded_features.size(0)\n",
    "        edge_probs = torch.zeros(num_nodes, num_nodes, device=node_features.device)\n",
    "        \n",
    "        for i in range(num_nodes):\n",
    "            for j in range(i + 1, num_nodes):\n",
    "                prob = torch.sigmoid(self.edge_predictor(\n",
    "                    encoded_features[i].unsqueeze(0),\n",
    "                    encoded_features[j].unsqueeze(0)\n",
    "                ).squeeze())\n",
    "                edge_probs[i, j] = prob\n",
    "                edge_probs[j, i] = prob  # Symmetric\n",
    "        \n",
    "        # Apply sparsity threshold\n",
    "        adj_matrix = (edge_probs > self.sparsity_threshold).float()\n",
    "        \n",
    "        # Convert to edge_index format\n",
    "        edge_indices = torch.nonzero(adj_matrix, as_tuple=True)\n",
    "        edge_index = torch.stack(edge_indices, dim=0)\n",
    "        edge_weights = edge_probs[edge_indices]\n",
    "        \n",
    "        return edge_index, edge_weights, encoded_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Enhanced Multi-Modal Recovery GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalRecoveryGNN(nn.Module):\n",
    "    \"\"\"Enhanced Multi-Modal Recovery GNN with Temporal and Adaptive Components\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim: int = 64, num_heads: int = 8):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        # Multi-scale temporal processing\n",
    "        self.temporal_conv = MultiScaleTemporalConv(\n",
    "            in_channels=hidden_dim, \n",
    "            out_channels=hidden_dim,\n",
    "            scales=[1, 3, 5, 7]\n",
    "        )\n",
    "        \n",
    "        # Adaptive graph learning\n",
    "        self.graph_learner = AdaptiveGraphLearner(\n",
    "            input_dim=hidden_dim,\n",
    "            hidden_dim=hidden_dim\n",
    "        )\n",
    "        \n",
    "        # Enhanced multi-head attention for cross-modal relationships\n",
    "        self.cross_modal_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Specialized processors for different modalities\n",
    "        self.physio_processor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        self.subjective_processor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        self.temporal_processor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        # Graph convolution layers\n",
    "        self.gcn_layers = nn.ModuleList([\n",
    "            GCNConv(hidden_dim, hidden_dim) for _ in range(2)\n",
    "        ])\n",
    "        \n",
    "        # Residual connections\n",
    "        self.residual_weights = nn.Parameter(torch.ones(2))\n",
    "        \n",
    "    def forward(self, x, edge_index=None, edge_attr=None, batch=None, athlete_idx=None):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Learn adaptive graph structure if not provided\n",
    "        if edge_index is None:\n",
    "            edge_index, edge_weights, x = self.graph_learner(x, athlete_idx)\n",
    "        else:\n",
    "            edge_weights = edge_attr if edge_attr is not None else torch.ones(edge_index.size(1), device=x.device)\n",
    "        \n",
    "        # Apply temporal convolutions to capture multi-scale patterns\n",
    "        if x.dim() == 2:\n",
    "            x_temporal = x.unsqueeze(1)  # (nodes, 1, features)\n",
    "        else:\n",
    "            x_temporal = x\n",
    "            \n",
    "        x_temporal = self.temporal_conv(x_temporal)\n",
    "        x = x_temporal.squeeze(1) if x_temporal.size(1) == 1 else x_temporal.mean(dim=1)\n",
    "        \n",
    "        # Node type-specific processing\n",
    "        node_features = []\n",
    "        for i in range(batch_size):\n",
    "            if i < 3:  # Physiological nodes\n",
    "                processed = self.physio_processor(x[i].unsqueeze(0))\n",
    "            elif i < 6:  # Subjective nodes\n",
    "                processed = self.subjective_processor(x[i].unsqueeze(0))\n",
    "            elif i < 12:  # Temporal nodes\n",
    "                processed = self.temporal_processor(x[i].unsqueeze(0))\n",
    "            else:  # Identity node\n",
    "                processed = x[i].unsqueeze(0)\n",
    "            node_features.append(processed)\n",
    "        \n",
    "        if node_features:\n",
    "            x_processed = torch.cat(node_features, dim=0)\n",
    "        else:\n",
    "            x_processed = x\n",
    "            \n",
    "        # Multi-layer graph convolution with residual connections (Equation 2)\n",
    "        h = x_processed\n",
    "        for i, gcn in enumerate(self.gcn_layers):\n",
    "            h_new = gcn(h, edge_index, edge_weights)\n",
    "            h = self.residual_weights[i] * h + (1 - self.residual_weights[i]) * h_new\n",
    "            h = F.gelu(h)\n",
    "            h = F.dropout(h, p=0.1, training=self.training)\n",
    "        \n",
    "        # Cross-modal attention for final refinement\n",
    "        if h.size(0) > 1:\n",
    "            h_attended, attention_weights = self.cross_modal_attention(\n",
    "                h.unsqueeze(0), h.unsqueeze(0), h.unsqueeze(0)\n",
    "            )\n",
    "            h = h_attended.squeeze(0)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Temporal Attention Recovery Network (TARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalAttentionRecoveryNetwork(nn.Module):\n",
    "    \"\"\"Temporal Attention Recovery Network (TARN) - Core Innovation\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128, num_layers: int = 3, num_heads: int = 8):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_projection = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        # Multi-layer recovery-specific GNN\n",
    "        self.recovery_layers = nn.ModuleList([\n",
    "            MultiModalRecoveryGNN(hidden_dim, num_heads) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Temporal attention for time-aware processing\n",
    "        self.temporal_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Graph-level representation\n",
    "        self.graph_pooling = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),  # Mean + max pooling\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Individual recovery signature learning\n",
    "        self.signature_learning = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + 4, hidden_dim),  # Graph + athlete features\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch, athlete_idx):\n",
    "        \"\"\"Forward pass through TARN\"\"\"\n",
    "        \n",
    "        # Project input features\n",
    "        h = self.input_projection(x)\n",
    "        \n",
    "        # Multi-layer recovery-specific message passing\n",
    "        for layer in self.recovery_layers:\n",
    "            h_new = layer(h, edge_index, edge_attr, batch)\n",
    "            h = h + h_new  # Residual connection\n",
    "            h = F.layer_norm(h, h.shape[-1:])  # Normalize\n",
    "        \n",
    "        # Temporal attention (if batch contains multiple time steps)\n",
    "        if batch is not None:\n",
    "            unique_batches = torch.unique(batch)\n",
    "            attended_features = []\n",
    "            \n",
    "            for b in unique_batches:\n",
    "                mask = (batch == b)\n",
    "                graph_nodes = h[mask].unsqueeze(0)  # Add batch dimension\n",
    "                \n",
    "                # Self-attention within graph\n",
    "                attended, attention_weights = self.temporal_attention(\n",
    "                    graph_nodes, graph_nodes, graph_nodes\n",
    "                )\n",
    "                attended_features.append(attended.squeeze(0))\n",
    "            \n",
    "            h = torch.cat(attended_features, dim=0)\n",
    "        \n",
    "        # Graph-level pooling\n",
    "        if batch is not None:\n",
    "            graph_features = []\n",
    "            for b in torch.unique(batch):\n",
    "                mask = (batch == b)\n",
    "                graph_nodes = h[mask]\n",
    "                \n",
    "                # Mean and max pooling\n",
    "                mean_pool = torch.mean(graph_nodes, dim=0)\n",
    "                max_pool = torch.max(graph_nodes, dim=0)[0]\n",
    "                \n",
    "                graph_repr = torch.cat([mean_pool, max_pool])\n",
    "                graph_features.append(graph_repr)\n",
    "            \n",
    "            graph_features = torch.stack(graph_features)\n",
    "        else:\n",
    "            # Single graph case\n",
    "            mean_pool = torch.mean(h, dim=0)\n",
    "            max_pool = torch.max(h, dim=0)[0]\n",
    "            graph_features = torch.cat([mean_pool, max_pool]).unsqueeze(0)\n",
    "        \n",
    "        # Apply graph pooling transformation\n",
    "        graph_features = self.graph_pooling(graph_features)\n",
    "        \n",
    "        # Individual recovery signature learning\n",
    "        if athlete_idx is not None:\n",
    "            # Add athlete-specific features\n",
    "            athlete_features = torch.zeros(graph_features.size(0), 4, device=graph_features.device)\n",
    "            if isinstance(athlete_idx, torch.Tensor):\n",
    "                athlete_features[:, 0] = athlete_idx.float() / 16.0\n",
    "            else:\n",
    "                athlete_features[:, 0] = athlete_idx / 16.0\n",
    "            \n",
    "            # Combine with graph features\n",
    "            combined_features = torch.cat([graph_features, athlete_features], dim=-1)\n",
    "            recovery_signature = self.signature_learning(combined_features)\n",
    "            \n",
    "            # Final representation\n",
    "            final_features = torch.cat([graph_features, recovery_signature], dim=-1)\n",
    "        else:\n",
    "            final_features = graph_features\n",
    "        \n",
    "        return final_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Contrastive Learning Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveEncoder(nn.Module):\n",
    "    \"\"\"Encoder for contrastive self-supervised pre-training\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128, projection_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.encoder = TemporalAttentionRecoveryNetwork(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=2,\n",
    "            num_heads=4\n",
    "        )\n",
    "        \n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + hidden_dim // 2, projection_dim),\n",
    "            nn.LayerNorm(projection_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(projection_dim, projection_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, batch=None, athlete_idx=None):\n",
    "        # Get representations from encoder\n",
    "        features = self.encoder(x, edge_index, edge_attr, batch, athlete_idx)\n",
    "        \n",
    "        # Project to contrastive space\n",
    "        projections = self.projector(features)\n",
    "        \n",
    "        return features, projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Main GraphRec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRecModel(nn.Module):\n",
    "    \"\"\"Enhanced GraphRec Model with Contrastive Pre-training Support\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128, num_athletes: int = 16, \n",
    "                 use_pretrained: bool = False, pretrained_encoder=None):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_athletes = num_athletes\n",
    "        self.use_pretrained = use_pretrained\n",
    "        \n",
    "        # Core TARN network (potentially pre-trained)\n",
    "        if use_pretrained and pretrained_encoder is not None:\n",
    "            self.tarn = pretrained_encoder.encoder\n",
    "            # Freeze pre-trained weights initially\n",
    "            for param in self.tarn.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            self.tarn = TemporalAttentionRecoveryNetwork(\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                num_layers=3,\n",
    "                num_heads=8\n",
    "            )\n",
    "        \n",
    "        # Multi-task prediction heads\n",
    "        final_dim = hidden_dim + hidden_dim // 2\n",
    "        \n",
    "        # Primary task: Next-day readiness prediction\n",
    "        self.readiness_predictor = nn.Sequential(\n",
    "            nn.Linear(final_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Secondary task: Recovery quality score\n",
    "        self.recovery_quality_predictor = nn.Sequential(\n",
    "            nn.Linear(final_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Tertiary task: Training readiness classification\n",
    "        self.training_readiness_classifier = nn.Sequential(\n",
    "            nn.Linear(final_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Quaternary task: Overreaching risk detection\n",
    "        self.overreach_detector = nn.Sequential(\n",
    "            nn.Linear(final_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Task importance weighting\n",
    "        self.task_attention = nn.Sequential(\n",
    "            nn.Linear(final_dim, 4),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "    \n",
    "    def unfreeze_encoder(self):\n",
    "        \"\"\"Unfreeze pre-trained encoder for fine-tuning\"\"\"\n",
    "        if self.use_pretrained:\n",
    "            for param in self.tarn.parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch=None, athlete_idx=None):\n",
    "        \"\"\"Forward pass through GraphRec\"\"\"\n",
    "        \n",
    "        # Core TARN processing\n",
    "        recovery_features = self.tarn(x, edge_index, edge_attr, batch, athlete_idx)\n",
    "        \n",
    "        # Multi-task predictions\n",
    "        readiness_pred = self.readiness_predictor(recovery_features)\n",
    "        quality_pred = self.recovery_quality_predictor(recovery_features)\n",
    "        training_pred = self.training_readiness_classifier(recovery_features)\n",
    "        overreach_pred = self.overreach_detector(recovery_features)\n",
    "        \n",
    "        # Task importance weighting\n",
    "        task_weights = self.task_attention(recovery_features)\n",
    "        \n",
    "        return {\n",
    "            'readiness': readiness_pred,\n",
    "            'quality': quality_pred,\n",
    "            'training': training_pred,\n",
    "            'overreach': overreach_pred,\n",
    "            'task_weights': task_weights,\n",
    "            'features': recovery_features\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Physics-Informed Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedLoss(nn.Module):\n",
    "    \"\"\"Physics-informed loss with physiological constraints\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Physiological bounds (normalized values)\n",
    "        self.hrv_bounds = (0.0, 1.0)\n",
    "        self.sleep_efficiency_bounds = (0.3, 1.0)\n",
    "        self.readiness_bounds = (0.0, 1.0)\n",
    "        self.fatigue_bounds = (0.0, 1.0)\n",
    "        \n",
    "    def compute_physics_violations(self, predictions: Dict, node_features: torch.Tensor = None):\n",
    "        \"\"\"Compute violations of physiological constraints (Equations 5-7)\"\"\"\n",
    "        violations = []\n",
    "        \n",
    "        # Readiness-quality correlation constraint\n",
    "        readiness = predictions['readiness'].squeeze()\n",
    "        quality = predictions['quality'].squeeze()\n",
    "        \n",
    "        readiness_quality_violation = torch.relu(-torch.corrcoef(torch.stack([readiness, quality]))[0, 1])\n",
    "        violations.append(readiness_quality_violation)\n",
    "        \n",
    "        # Overreach risk constraint\n",
    "        overreach = predictions['overreach'].squeeze()\n",
    "        fatigue_proxy = 1.0 - readiness\n",
    "        expected_correlation = torch.corrcoef(torch.stack([fatigue_proxy, overreach]))[0, 1]\n",
    "        overreach_violation = torch.relu(-expected_correlation)\n",
    "        violations.append(overreach_violation)\n",
    "        \n",
    "        # Bounds violations\n",
    "        readiness_bounds_violation = (\n",
    "            torch.relu(self.readiness_bounds[0] - readiness).mean() +\n",
    "            torch.relu(readiness - self.readiness_bounds[1]).mean()\n",
    "        )\n",
    "        violations.append(readiness_bounds_violation)\n",
    "        \n",
    "        return torch.stack(violations).mean()\n",
    "    \n",
    "    def forward(self, predictions: Dict, node_features: torch.Tensor = None, physics_weight: float = 0.1):\n",
    "        \"\"\"Compute physics-informed loss\"\"\"\n",
    "        physics_loss = self.compute_physics_violations(predictions, node_features)\n",
    "        return physics_weight * physics_loss\n",
    "\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"Contrastive learning loss for self-supervised pre-training\"\"\"\n",
    "    \n",
    "    def __init__(self, temperature: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def forward(self, z1: torch.Tensor, z2: torch.Tensor):\n",
    "        \"\"\"InfoNCE loss for contrastive learning (Equation 8)\"\"\"\n",
    "        # Normalize embeddings\n",
    "        z1 = F.normalize(z1, dim=-1)\n",
    "        z2 = F.normalize(z2, dim=-1)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity_matrix = torch.matmul(z1, z2.T) / self.temperature\n",
    "        \n",
    "        # Labels are diagonal (positive pairs)\n",
    "        batch_size = z1.size(0)\n",
    "        labels = torch.arange(batch_size, device=z1.device)\n",
    "        \n",
    "        loss = F.cross_entropy(similarity_matrix, labels)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class CorrelationLoss(nn.Module):\n",
    "    \"\"\"Loss function that directly optimizes correlation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, predictions: torch.Tensor, targets: torch.Tensor):\n",
    "        \"\"\"Compute negative correlation as loss (maximize correlation)\"\"\"\n",
    "        if predictions.dim() > 1:\n",
    "            predictions = predictions.flatten()\n",
    "        if targets.dim() > 1:\n",
    "            targets = targets.flatten()\n",
    "            \n",
    "        # Compute Pearson correlation\n",
    "        vx = predictions - torch.mean(predictions)\n",
    "        vy = targets - torch.mean(targets)\n",
    "        \n",
    "        correlation = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)) + 1e-8)\n",
    "        \n",
    "        return -correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Enhanced Multi-Objective Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRecLoss(nn.Module):\n",
    "    \"\"\"Enhanced multi-objective loss function for recovery optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, task_weights: List[float] = [0.4, 0.3, 0.2, 0.1], use_correlation_loss: bool = True):\n",
    "        super().__init__()\n",
    "        self.task_weights = task_weights\n",
    "        self.use_correlation_loss = use_correlation_loss\n",
    "        \n",
    "        # Standard losses\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        \n",
    "        # Enhanced losses\n",
    "        self.correlation_loss = CorrelationLoss()\n",
    "        self.physics_loss = PhysicsInformedLoss()\n",
    "        self.contrastive_loss = ContrastiveLoss()\n",
    "        \n",
    "        # Focal loss parameters\n",
    "        self.focal_alpha = 0.25\n",
    "        self.focal_gamma = 2.0\n",
    "        \n",
    "    def focal_loss(self, predictions: torch.Tensor, targets: torch.Tensor):\n",
    "        \"\"\"Focal loss for handling imbalanced data\"\"\"\n",
    "        ce_loss = F.binary_cross_entropy_with_logits(predictions, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.focal_alpha * (1-pt)**self.focal_gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "    \n",
    "    def forward(self, predictions: Dict, targets: torch.Tensor, task_attention_weights: torch.Tensor = None, \n",
    "                node_features: torch.Tensor = None, epoch: int = 0, max_epochs: int = 150):\n",
    "        \"\"\"Calculate enhanced multi-objective loss\"\"\"\n",
    "        \n",
    "        # Handle different target tensor shapes\n",
    "        if targets.dim() == 0:\n",
    "            targets = torch.tensor([[0.5, 0.5, 0.5, 0.5]], device=targets.device)\n",
    "        elif targets.dim() == 1:\n",
    "            if targets.size(0) == 4:\n",
    "                targets = targets.unsqueeze(0)\n",
    "            else:\n",
    "                targets = targets.view(-1, 4)\n",
    "        \n",
    "        batch_size = predictions['readiness'].size(0)\n",
    "        \n",
    "        if targets.size(0) != batch_size:\n",
    "            if targets.size(0) == 1:\n",
    "                targets = targets.expand(batch_size, -1)\n",
    "            else:\n",
    "                raise ValueError(f\"Target batch size {targets.size(0)} doesn't match prediction batch size {batch_size}\")\n",
    "        \n",
    "        # Extract predictions and targets\n",
    "        readiness_pred = predictions['readiness'].squeeze(-1)\n",
    "        quality_pred = predictions['quality'].squeeze(-1)\n",
    "        training_pred = predictions['training'].squeeze(-1)\n",
    "        overreach_pred = predictions['overreach'].squeeze(-1)\n",
    "        \n",
    "        # Extract targets with proper dimensions\n",
    "        if targets.size(1) >= 4:\n",
    "            readiness_target = targets[:, 0]\n",
    "            quality_target = targets[:, 1]\n",
    "            training_target = targets[:, 2]\n",
    "            overreach_target = targets[:, 3]\n",
    "        else:\n",
    "            # Fallback for malformed targets\n",
    "            readiness_target = torch.zeros_like(readiness_pred)\n",
    "            quality_target = torch.zeros_like(quality_pred) \n",
    "            training_target = torch.zeros_like(training_pred)\n",
    "            overreach_target = torch.zeros_like(overreach_pred)\n",
    "        \n",
    "        # Standard losses with correlation enhancement\n",
    "        if self.use_correlation_loss and batch_size > 1:\n",
    "            readiness_loss = 0.5 * self.mse_loss(readiness_pred, readiness_target) + 0.5 * self.correlation_loss(readiness_pred, readiness_target)\n",
    "            quality_loss = 0.5 * self.mse_loss(quality_pred, quality_target) + 0.5 * self.correlation_loss(quality_pred, quality_target)\n",
    "            training_loss = 0.5 * self.mse_loss(training_pred, training_target) + 0.5 * self.correlation_loss(training_pred, training_target)\n",
    "        else:\n",
    "            readiness_loss = self.mse_loss(readiness_pred, readiness_target)\n",
    "            quality_loss = self.mse_loss(quality_pred, quality_target)\n",
    "            training_loss = self.mse_loss(training_pred, training_target)\n",
    "        \n",
    "        # Focal loss for overreach detection\n",
    "        overreach_loss = self.focal_loss(overreach_pred, overreach_target)\n",
    "        \n",
    "        # Base weighted loss\n",
    "        base_loss = (\n",
    "            self.task_weights[0] * readiness_loss +\n",
    "            self.task_weights[1] * quality_loss +\n",
    "            self.task_weights[2] * training_loss +\n",
    "            self.task_weights[3] * overreach_loss\n",
    "        )\n",
    "        \n",
    "        # Physics-informed loss with dynamic weighting\n",
    "        physics_loss_val = torch.tensor(0.0, device=readiness_pred.device)\n",
    "        if batch_size > 1:\n",
    "            physics_weight = max(0.1, 0.5 * (1 - epoch / max_epochs))\n",
    "            try:\n",
    "                physics_loss_val = self.physics_loss(predictions, node_features, physics_weight)\n",
    "            except Exception:\n",
    "                physics_loss_val = torch.tensor(0.0, device=readiness_pred.device)\n",
    "        \n",
    "        # Adaptive weighting based on attention\n",
    "        if task_attention_weights is not None:\n",
    "            attention_weights = torch.mean(task_attention_weights, dim=0)\n",
    "            adaptive_loss = (\n",
    "                attention_weights[0] * readiness_loss +\n",
    "                attention_weights[1] * quality_loss +\n",
    "                attention_weights[2] * training_loss +\n",
    "                attention_weights[3] * overreach_loss\n",
    "            )\n",
    "            total_loss = 0.6 * base_loss + 0.3 * adaptive_loss + 0.1 * physics_loss_val\n",
    "        else:\n",
    "            total_loss = 0.9 * base_loss + 0.1 * physics_loss_val\n",
    "        \n",
    "        return {\n",
    "            'total_loss': total_loss,\n",
    "            'readiness_loss': readiness_loss,\n",
    "            'quality_loss': quality_loss,\n",
    "            'training_loss': training_loss,\n",
    "            'overreach_loss': overreach_loss,\n",
    "            'physics_loss': physics_loss_val\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Contrastive Pre-training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_contrastive_encoder(graphs: List[Data], input_dim: int, hidden_dim: int = 128, \n",
    "                                epochs: int = 50, batch_size: int = 64):\n",
    "    \"\"\"Pre-train encoder using contrastive learning\"\"\"\n",
    "    \n",
    "    # Create contrastive pairs\n",
    "    processor = DataProcessor()\n",
    "    contrastive_pairs = processor.create_contrastive_pairs(graphs)\n",
    "    \n",
    "    if not contrastive_pairs:\n",
    "        return None\n",
    "    \n",
    "    # Initialize encoder\n",
    "    encoder = ContrastiveEncoder(input_dim, hidden_dim).to(device)\n",
    "    contrastive_loss = ContrastiveLoss(temperature=0.5)\n",
    "    optimizer = torch.optim.AdamW(encoder.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    \n",
    "    # Training loop\n",
    "    encoder.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        random.shuffle(contrastive_pairs)\n",
    "        \n",
    "        for i in range(0, len(contrastive_pairs), batch_size):\n",
    "            batch_pairs = contrastive_pairs[i:i + batch_size]\n",
    "            \n",
    "            if len(batch_pairs) < 2:\n",
    "                continue\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            z1_list, z2_list = [], []\n",
    "            \n",
    "            for graph1, graph2 in batch_pairs:\n",
    "                try:\n",
    "                    # Move graphs to device\n",
    "                    graph1.x = graph1.x.to(device)\n",
    "                    graph1.edge_index = graph1.edge_index.to(device)\n",
    "                    graph1.edge_attr = graph1.edge_attr.to(device)\n",
    "                    graph2.x = graph2.x.to(device)\n",
    "                    graph2.edge_index = graph2.edge_index.to(device)\n",
    "                    graph2.edge_attr = graph2.edge_attr.to(device)\n",
    "                    \n",
    "                    _, z1 = encoder(graph1.x, graph1.edge_index, graph1.edge_attr, \n",
    "                                  None, getattr(graph1, 'athlete_idx', None))\n",
    "                    _, z2 = encoder(graph2.x, graph2.edge_index, graph2.edge_attr,\n",
    "                                  None, getattr(graph2, 'athlete_idx', None))\n",
    "                    \n",
    "                    z1_list.append(z1.squeeze() if z1.dim() > 1 else z1)\n",
    "                    z2_list.append(z2.squeeze() if z2.dim() > 1 else z2)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            if len(z1_list) > 1:\n",
    "                try:\n",
    "                    z1_batch = torch.stack(z1_list)\n",
    "                    z2_batch = torch.stack(z2_list)\n",
    "                    \n",
    "                    loss = contrastive_loss(z1_batch, z2_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    num_batches += 1\n",
    "                except Exception:\n",
    "                    continue\n",
    "        \n",
    "        if num_batches > 0:\n",
    "            avg_loss = total_loss / num_batches\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Pre-training Epoch {epoch+1:3d} | Contrastive Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graphrec(use_contrastive_pretraining: bool = True, use_data_augmentation: bool = True):\n",
    "    \"\"\"Train the GraphRec system\"\"\"\n",
    "    \n",
    "    # Data processing\n",
    "    processor = DataProcessor()\n",
    "    graphs, stats = processor.process_all_participants()\n",
    "    \n",
    "    # Apply data augmentation if requested\n",
    "    if use_data_augmentation:\n",
    "        original_count = len(graphs)\n",
    "    \n",
    "    if not graphs:\n",
    "        return\n",
    "    \n",
    "    print(f\"Generated {len(graphs)} recovery graphs\")\n",
    "    \n",
    "    # Dataset statistics\n",
    "    total_samples = sum(s['samples'] for s in stats.values())\n",
    "    total_graphs = sum(s['graphs'] for s in stats.values())\n",
    "    print(f\"Total samples: {total_samples}, Total graphs: {total_graphs}, Participants: {len(stats)}\")\n",
    "    \n",
    "    # Data splitting\n",
    "    train_graphs, temp_graphs = train_test_split(graphs, test_size=0.4, random_state=42)\n",
    "    val_graphs, test_graphs = train_test_split(temp_graphs, test_size=0.5, random_state=42)\n",
    "    \n",
    "    print(f\"Train/Val/Test: {len(train_graphs)}/{len(val_graphs)}/{len(test_graphs)}\")\n",
    "    \n",
    "    # Create data loaders with device transfer\n",
    "    train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_graphs, batch_size=64, shuffle=False)\n",
    "    test_loader = DataLoader(test_graphs, batch_size=64, shuffle=False)\n",
    "    \n",
    "    def move_batch_to_device(batch, device):\n",
    "        batch.x = batch.x.to(device)\n",
    "        batch.edge_index = batch.edge_index.to(device)\n",
    "        batch.edge_attr = batch.edge_attr.to(device)\n",
    "        batch.y = batch.y.to(device)\n",
    "        if hasattr(batch, 'batch'):\n",
    "            batch.batch = batch.batch.to(device)\n",
    "        return batch\n",
    "    \n",
    "    # Model setup with optional contrastive pre-training\n",
    "    input_dim = train_graphs[0].x.size(1)\n",
    "    \n",
    "    pretrained_encoder = None\n",
    "    if use_contrastive_pretraining:\n",
    "        pretrained_encoder = pretrain_contrastive_encoder(\n",
    "            train_graphs, input_dim, hidden_dim=128, epochs=30\n",
    "        )\n",
    "    \n",
    "    model = GraphRecModel(\n",
    "        input_dim=input_dim, \n",
    "        hidden_dim=128, \n",
    "        num_athletes=16,\n",
    "        use_pretrained=use_contrastive_pretraining,\n",
    "        pretrained_encoder=pretrained_encoder\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"Model Architecture: Input dim: {input_dim}, Hidden dim: 128, Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Training setup with enhanced loss function\n",
    "    criterion = GraphRecLoss(use_correlation_loss=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "    \n",
    "    # Unfreeze pre-trained encoder after warmup\n",
    "    warmup_epochs = 20\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    patience = 0\n",
    "    max_patience = 25\n",
    "    \n",
    "    for epoch in range(150):\n",
    "        # Unfreeze encoder after warmup\n",
    "        if epoch == warmup_epochs and model.use_pretrained:\n",
    "            model.unfreeze_encoder()\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] *= 0.1\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        all_predictions = {'readiness': [], 'quality': [], 'training': [], 'overreach': []}\n",
    "        all_targets = {'readiness': [], 'quality': [], 'training': [], 'overreach': []}\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            batch = move_batch_to_device(batch, device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(\n",
    "                batch.x, \n",
    "                batch.edge_index, \n",
    "                batch.edge_attr,\n",
    "                batch.batch,\n",
    "                getattr(batch, 'athlete_idx', None)\n",
    "            )\n",
    "            \n",
    "            # Loss calculation with enhanced features\n",
    "            loss_dict = criterion(\n",
    "                predictions, \n",
    "                batch.y, \n",
    "                predictions['task_weights'],\n",
    "                batch.x,\n",
    "                epoch,\n",
    "                150\n",
    "            )\n",
    "            loss = loss_dict['total_loss']\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Collect predictions for metrics\n",
    "            all_predictions['readiness'].extend(predictions['readiness'].detach().cpu().numpy().flatten())\n",
    "            all_predictions['quality'].extend(predictions['quality'].detach().cpu().numpy().flatten())\n",
    "            all_predictions['training'].extend(predictions['training'].detach().cpu().numpy().flatten())\n",
    "            all_predictions['overreach'].extend(predictions['overreach'].detach().cpu().numpy().flatten())\n",
    "            \n",
    "            # Handle PyG batching of y tensors\n",
    "            if batch.y.dim() == 2:\n",
    "                all_targets['readiness'].extend(batch.y[:, 0].cpu().numpy())\n",
    "                all_targets['quality'].extend(batch.y[:, 1].cpu().numpy())\n",
    "                all_targets['training'].extend(batch.y[:, 2].cpu().numpy())\n",
    "                all_targets['overreach'].extend(batch.y[:, 3].cpu().numpy())\n",
    "            elif batch.y.dim() == 1:\n",
    "                batch_size = len(batch.ptr) - 1\n",
    "                y_reshaped = batch.y.view(batch_size, 4)\n",
    "                all_targets['readiness'].extend(y_reshaped[:, 0].cpu().numpy())\n",
    "                all_targets['quality'].extend(y_reshaped[:, 1].cpu().numpy())\n",
    "                all_targets['training'].extend(y_reshaped[:, 2].cpu().numpy())\n",
    "                all_targets['overreach'].extend(y_reshaped[:, 3].cpu().numpy())\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_predictions = {'readiness': [], 'quality': [], 'training': [], 'overreach': []}\n",
    "        val_targets = {'readiness': [], 'quality': [], 'training': [], 'overreach': []}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = move_batch_to_device(batch, device)\n",
    "                \n",
    "                predictions = model(\n",
    "                    batch.x,\n",
    "                    batch.edge_index,\n",
    "                    batch.edge_attr,\n",
    "                    batch.batch,\n",
    "                    getattr(batch, 'athlete_idx', None)\n",
    "                )\n",
    "                \n",
    "                loss_dict = criterion(\n",
    "                    predictions, \n",
    "                    batch.y, \n",
    "                    predictions['task_weights'],\n",
    "                    batch.x,\n",
    "                    epoch,\n",
    "                    150\n",
    "                )\n",
    "                val_loss += loss_dict['total_loss'].item()\n",
    "                \n",
    "                # Collect validation predictions\n",
    "                val_predictions['readiness'].extend(predictions['readiness'].detach().cpu().numpy().flatten())\n",
    "                val_predictions['quality'].extend(predictions['quality'].detach().cpu().numpy().flatten())\n",
    "                val_predictions['training'].extend(predictions['training'].detach().cpu().numpy().flatten())\n",
    "                val_predictions['overreach'].extend(predictions['overreach'].detach().cpu().numpy().flatten())\n",
    "                \n",
    "                # Handle PyG batching of y tensors\n",
    "                if batch.y.dim() == 2:\n",
    "                    val_targets['readiness'].extend(batch.y[:, 0].cpu().numpy())\n",
    "                    val_targets['quality'].extend(batch.y[:, 1].cpu().numpy())\n",
    "                    val_targets['training'].extend(batch.y[:, 2].cpu().numpy())\n",
    "                    val_targets['overreach'].extend(batch.y[:, 3].cpu().numpy())\n",
    "                elif batch.y.dim() == 1:\n",
    "                    batch_size = len(batch.ptr) - 1\n",
    "                    y_reshaped = batch.y.view(batch_size, 4)\n",
    "                    val_targets['readiness'].extend(y_reshaped[:, 0].cpu().numpy())\n",
    "                    val_targets['quality'].extend(y_reshaped[:, 1].cpu().numpy())\n",
    "                    val_targets['training'].extend(y_reshaped[:, 2].cpu().numpy())\n",
    "                    val_targets['overreach'].extend(y_reshaped[:, 3].cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Readiness prediction accuracy (main metric)\n",
    "        readiness_mae = mean_absolute_error(val_targets['readiness'], val_predictions['readiness'])\n",
    "        readiness_rmse = np.sqrt(mean_squared_error(val_targets['readiness'], val_predictions['readiness']))\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "        \n",
    "        # Progress reporting\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1:3d} | Loss: {avg_train_loss:.4f}/{avg_val_loss:.4f} | \"\n",
    "                  f\"Readiness MAE: {readiness_mae:.3f} | RMSE: {readiness_rmse:.3f}\")\n",
    "        \n",
    "        if patience >= max_patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Final evaluation\n",
    "    model.eval()\n",
    "    test_predictions = {'readiness': [], 'quality': [], 'training': [], 'overreach': []}\n",
    "    test_targets = {'readiness': [], 'quality': [], 'training': [], 'overreach': []}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = move_batch_to_device(batch, device)\n",
    "            \n",
    "            predictions = model(\n",
    "                batch.x,\n",
    "                batch.edge_index,\n",
    "                batch.edge_attr,\n",
    "                batch.batch,\n",
    "                getattr(batch, 'athlete_idx', None)\n",
    "            )\n",
    "            \n",
    "            test_predictions['readiness'].extend(predictions['readiness'].detach().cpu().numpy().flatten())\n",
    "            test_predictions['quality'].extend(predictions['quality'].detach().cpu().numpy().flatten())\n",
    "            test_predictions['training'].extend(predictions['training'].detach().cpu().numpy().flatten())\n",
    "            test_predictions['overreach'].extend(predictions['overreach'].detach().cpu().numpy().flatten())\n",
    "            \n",
    "            if batch.y.dim() == 2:\n",
    "                test_targets['readiness'].extend(batch.y[:, 0].cpu().numpy())\n",
    "                test_targets['quality'].extend(batch.y[:, 1].cpu().numpy())\n",
    "                test_targets['training'].extend(batch.y[:, 2].cpu().numpy())\n",
    "                test_targets['overreach'].extend(batch.y[:, 3].cpu().numpy())\n",
    "            elif batch.y.dim() == 1:\n",
    "                batch_size = len(batch.ptr) - 1\n",
    "                y_reshaped = batch.y.view(batch_size, 4)\n",
    "                test_targets['readiness'].extend(y_reshaped[:, 0].cpu().numpy())\n",
    "                test_targets['quality'].extend(y_reshaped[:, 1].cpu().numpy())\n",
    "                test_targets['training'].extend(y_reshaped[:, 2].cpu().numpy())\n",
    "                test_targets['overreach'].extend(y_reshaped[:, 3].cpu().numpy())\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    results = {}\n",
    "    for task in ['readiness', 'quality', 'training', 'overreach']:\n",
    "        mae = mean_absolute_error(test_targets[task], test_predictions[task])\n",
    "        rmse = np.sqrt(mean_squared_error(test_targets[task], test_predictions[task]))\n",
    "        correlation = np.corrcoef(test_targets[task], test_predictions[task])[0, 1]\n",
    "        \n",
    "        results[task] = {\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'correlation': correlation\n",
    "        }\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nGRAPHREC RESULTS:\")\n",
    "    print(\"=\" * 50)\n",
    "    for task, metrics in results.items():\n",
    "        print(f\"{task.upper()} Prediction:\")\n",
    "        print(f\"   MAE: {metrics['mae']:.4f}\")\n",
    "        print(f\"   RMSE: {metrics['rmse']:.4f}\")\n",
    "        print(f\"   Correlation: {metrics['correlation']:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    # Overall performance\n",
    "    avg_correlation = np.mean([r['correlation'] for r in results.values()])\n",
    "    avg_mae = np.mean([r['mae'] for r in results.values()])\n",
    "    \n",
    "    print(f\"OVERALL PERFORMANCE:\")\n",
    "    print(f\"   Average Correlation: {avg_correlation:.4f}\")\n",
    "    print(f\"   Average MAE: {avg_mae:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'results': results,\n",
    "        'processor': processor,\n",
    "        'model_config': {\n",
    "            'input_dim': input_dim,\n",
    "            'hidden_dim': 128,\n",
    "            'num_athletes': 16\n",
    "        }\n",
    "    }, 'graphrec_model.pth')\n",
    "    \n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1651 recovery graphs\n",
      "Total samples: 1747, Total graphs: 1651, Participants: 16\n",
      "Train/Val/Test: 990/330/331\n",
      "Model Architecture: Input dim: 9, Hidden dim: 128, Parameters: 922,577\n",
      "Epoch   1 | Loss: -0.2183/-0.3610 | Readiness MAE: 0.149 | RMSE: 0.182\n",
      "Epoch  10 | Loss: -0.3829/-0.3939 | Readiness MAE: 0.043 | RMSE: 0.062\n",
      "Epoch  20 | Loss: -0.3911/-0.3993 | Readiness MAE: 0.068 | RMSE: 0.086\n",
      "Epoch  30 | Loss: -0.3884/-0.3950 | Readiness MAE: 0.045 | RMSE: 0.062\n",
      "Epoch  40 | Loss: -0.3937/-0.3986 | Readiness MAE: 0.056 | RMSE: 0.072\n",
      "Epoch  50 | Loss: -0.3946/-0.4031 | Readiness MAE: 0.025 | RMSE: 0.044\n",
      "Epoch  60 | Loss: -0.3982/-0.4057 | Readiness MAE: 0.046 | RMSE: 0.059\n",
      "Epoch  70 | Loss: -0.4004/-0.4067 | Readiness MAE: 0.036 | RMSE: 0.048\n",
      "Epoch  80 | Loss: -0.4017/-0.4070 | Readiness MAE: 0.031 | RMSE: 0.045\n",
      "Epoch  90 | Loss: -0.4022/-0.4075 | Readiness MAE: 0.022 | RMSE: 0.039\n",
      "Epoch 100 | Loss: -0.4027/-0.4075 | Readiness MAE: 0.025 | RMSE: 0.041\n",
      "Epoch 110 | Loss: -0.4036/-0.4074 | Readiness MAE: 0.025 | RMSE: 0.041\n",
      "Early stopping at epoch 114\n",
      "\n",
      "GRAPHREC RESULTS:\n",
      "==================================================\n",
      "READINESS Prediction:\n",
      "   MAE: 0.0322\n",
      "   RMSE: 0.0423\n",
      "   Correlation: 0.9952\n",
      "\n",
      "QUALITY Prediction:\n",
      "   MAE: 0.0173\n",
      "   RMSE: 0.0244\n",
      "   Correlation: 0.9717\n",
      "\n",
      "TRAINING Prediction:\n",
      "   MAE: 0.0484\n",
      "   RMSE: 0.1035\n",
      "   Correlation: 0.9009\n",
      "\n",
      "OVERREACH Prediction:\n",
      "   MAE: 0.3434\n",
      "   RMSE: 0.3737\n",
      "   Correlation: 0.6714\n",
      "\n",
      "OVERALL PERFORMANCE:\n",
      "   Average Correlation: 0.8848\n",
      "   Average MAE: 0.1103\n"
     ]
    }
   ],
   "source": [
    "model, results = train_graphrec(\n",
    "    use_contrastive_pretraining=False,\n",
    "    use_data_augmentation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
